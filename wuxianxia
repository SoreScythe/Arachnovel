#!/usrb/bin/env python3
from time import sleep
from sys import argv, exit
from bs4 import BeautifulSoup as bs
from requests import get

base_url = 'https://m.mywuxiaworld.com/book/'
__main__ = 'wuxianxia'
# Simple function to fetch and return an urls content
def fetch(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}
    with get(url, headers=headers) as page:
        page.encoding = 'utf-8'
        return page.text

def parse_index(url):
    soup = bs(fetch(url), 'html.parser')
    chapter_index = bs(fetch(url + '/dir.html'), 'html.parser')
    # get novel title and author
    info = soup.find('meta', {'name':'keywords'}).get('content').split(',')
    title = info[0]
    author = info[2]

    # total chapters
    chapters = [[a.get('href'), a.get('title')] for a in chapter_index.find_all('a', {'class':'w100 flex-wrp flex-align-center flex-between pt10 pb10'})]
    print('Title: {}\nAuthor: {}\nChapters: {}'.format(title, author, len(chapters)))

def main():
    # check if an url is passed
    if len(argv) != 2:
        print('Usage: {} https://m.mywuxiaworld.com/book/Last_Wish_System/'.format(__main__))
        exit()
    if base_url in argv[1]:
        novel_url = argv[1]
    parse_index(novel_url)

if __name__ == '__main__':
    main()
